use std::collections::BTreeMap;
use std::io::{BufWriter, Write};
use std::fs::File;
use tauri::{AppHandle, Emitter};
use crate::state::{ProgressPayload, MACRO_CHUNK_SIZE, BUFFER_SIZE};
use rayon::prelude::*;
use std::time::{Instant, Duration};
use std::sync::{Arc};

pub struct FileProcessor;

impl FileProcessor {
    /// æ‰§è¡Œä¿åºè„±æ•æµæ°´çº¿
    pub fn run_ordered_pipeline(
        input_path: String,
        output_path: String,
        app_handle: AppHandle,
         // ğŸš€ æ–°å¢å‚æ•°ï¼šä» State ä¸­è·å–çš„å¼•æ“å¼•ç”¨
        engine: Arc<std::sync::RwLock<crate::engine::MaskEngine>>,
    ) -> Result<String, String> {
        let file = File::open(&input_path).map_err(|e| e.to_string())?;
        let mmap = unsafe { memmap2::Mmap::map(&file).map_err(|e| e.to_string())? };
        let file_size = mmap.len();
        let total_chunks = (file_size as f32 / MACRO_CHUNK_SIZE as f32).ceil() as usize;

        let (tx, rx) = crossbeam_channel::bounded::<(usize, Vec<u8>)>(rayon::current_num_threads() * 2);

        // é¡ºåºå†™å…¥çº¿ç¨‹
        let writer_handle = std::thread::spawn(move || -> Result<(), String> {
            let file_out = File::create(&output_path).map_err(|e| e.to_string())?;
            let mut writer = BufWriter::with_capacity(BUFFER_SIZE, file_out);
            let mut next_idx = 0;
            let mut pending_map = BTreeMap::new();
            let mut processed_count = 0;
            
             // ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šè¿›åº¦èŠ‚æµå˜é‡
            let mut last_emit_time = Instant::now();
            let mut last_percentage = -1.0;

        //     while let Ok((idx, data)) = rx.recv() {
        //         pending_map.insert(idx, data);
        //         while let Some(data) = pending_map.remove(&next_idx) {
        //             writer.write_all(&data).map_err(|e| e.to_string())?;
        //             next_idx += 1;
        //             processed_count += 1;
                    
        //             let _ = app_handle.emit("file-progress", ProgressPayload {
        //                 percentage: (processed_count as f32 / total_chunks as f32) * 100.0,
        //                 processed_mb: (processed_count * MACRO_CHUNK_SIZE) as f64 / 1024.0 / 1024.0,
        //             });
        //         }
        //     }
        //     writer.flush().map_err(|e| e.to_string())?;
        //     Ok(())
        // });

        while let Ok((idx, data)) = rx.recv() {
                pending_map.insert(idx, data);
                while let Some(data) = pending_map.remove(&next_idx) {
                    writer.write_all(&data).map_err(|e| e.to_string())?;
                    next_idx += 1;
                    processed_count += 1;
                    
                    let percentage = (processed_count as f32 / total_chunks as f32) * 100.0;
                    
                    // ğŸš€ æ ¸å¿ƒä¼˜åŒ–é€»è¾‘ï¼š
                    // åªæœ‰å½“æ—¶é—´è¶…è¿‡ 100ms ä¸”è¿›åº¦ç¡®å®æœ‰æ˜¾è‘—å˜åŒ–æ—¶æ‰å‘å°„äº‹ä»¶
                    if last_emit_time.elapsed() > Duration::from_millis(100) && (percentage - last_percentage).abs() >= 2.0 {
                        let _ = app_handle.emit("file-progress", ProgressPayload {
                            percentage,
                            processed_mb: (processed_count * MACRO_CHUNK_SIZE) as f64 / 1024.0 / 1024.0,
                        });
                        last_emit_time = Instant::now();
                        last_percentage = percentage;
                    }
                }
            }
            // ç¡®ä¿æœ€åå®Œæˆæ—¶å‘é€ 100%
            let _ = app_handle.emit("file-progress", ProgressPayload { percentage: 100.0, processed_mb: file_size as f64 / 1024.0 / 1024.0 });
            writer.flush().map_err(|e| e.to_string())?;
            Ok(())
        });

        // å¹¶è¡Œè®¡ç®—
        mmap.par_chunks(MACRO_CHUNK_SIZE)
            .enumerate()
            .for_each(|(idx, chunk)| {
                let mut out = Vec::with_capacity(chunk.len() + 2048);
                 // ğŸš€ è·å–è¯»é”
                let engine_lock = engine.read().unwrap();
                for line in chunk.split(|&b| b == b'\n') {
                    if !line.is_empty() {
                        out.extend_from_slice(&engine_lock.mask_line(line));
                    }
                    out.push(b'\n');
                }
                let _ = tx.send((idx, out));
            });

        drop(tx);
        writer_handle.join().map_err(|_| "Writer thread panicked")??;
        Ok("æ–‡ä»¶å¤„ç†æˆåŠŸ".into())
    }
}